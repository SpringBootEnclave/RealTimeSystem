{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "urlpage = 'http://www.fasttrack.co.uk/league-tables/tech-track-100/league-table/'\n",
    "page = urllib.request.urlopen(urlpage)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "table = soup.find('table', attrs = {\n",
    "  'class': 'tableSorter'\n",
    "})\n",
    "results = table.find_all('tr')\n",
    "print(\"Number of results\", len(results))\n",
    "rows = []\n",
    "rows.append(['Rank', 'Company Name', 'Webpage', 'Description', 'Location', 'Year end', 'Annual sales rise over 3 years', 'Sales Â£000s', 'Staff', 'Comments'])# print(rows)\n",
    "for result in results:\n",
    "    data = result.find_all('td')\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    rank = data[0].getText()\n",
    "    company = data[1].getText()\n",
    "    location = data[2].getText()\n",
    "    yearend = data[3].getText()\n",
    "    salesrise = data[4].getText()\n",
    "    sales = data[5].getText()\n",
    "    staff = data[6].getText()\n",
    "    comments = data[7].getText()\n",
    "    companyname = data[1].find('span', attrs = {\n",
    "    'class': 'company-name'\n",
    "    }).getText()\n",
    "    description = company.replace(companyname, '')\n",
    "    sales = sales.strip('*').strip('+').replace(',', '')\n",
    "\n",
    "\n",
    "    url = data[1].find('a').get('href')\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    try:\n",
    "        tableRow = soup.find('table').find_all('tr')[-1]\n",
    "        webpage = tableRow.find('a').get('href')\n",
    "    except:\n",
    "        webpage = None\n",
    "\n",
    "\n",
    "    rows.append([rank, companyname, webpage, description, location, yearend, salesrise, sales, staff, comments])\n",
    "\n",
    "print(rows)\n",
    "\n",
    "\n",
    "## Create csv and write rows to output file\n",
    "\n",
    "with open('baitap.csv','w', encoding='utf-8', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output)\n",
    "    csv_output.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"baitap.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Annual sales rise over 3 years'] = dataset['Annual sales rise over 3 years'].str.strip('%')\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
